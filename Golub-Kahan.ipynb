{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidiagonalization with Householder Reflectors: Golub-Kahan Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bidiagonalization method Golub and Kahan proposed in 1965 sought to eliminate computational difficulties in calculating the singular value decomposition of matrices [1]. \n",
    "\n",
    "Singular value decomposition (SVD) is a powerful tool in machine learning. The SVD algorithm factors a matrix: $A$ into one matrix with **orthogonal columns**, one with **orthogonal rows**, and a diagonal matrix which contains the **singular values** of the original matrix [2]. \n",
    "\n",
    "SVD is used in dimensionality reduction with numerous applications including: topic modeling, recommender systems, and image filtering. A great example matching customers to movies can be found at [3].\n",
    "\n",
    "\n",
    "The resulting singular values: $\\Sigma$ are relative importance factors of the original matrix.\n",
    "\n",
    "SVD of matrix $A$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A = U\\Sigma V^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bidiagonalization is the first step in many matrix decomposition algorithms where the original matrix: $A$ is **ill-conditioned** or **rank deficient**; often this is the case in image blurring scenarios [4]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Golub-Kahan method tranforms matrix $A$ into a **bidiagonal matrix: $J$**. \n",
    "\n",
    "Using **Householder reflectors**, applied alternating from the left and from the right, matrix entries are zeroed leaving behind a bidiagonal of non-zero values. The resulting bidiagonal matrix $J$ can then be diagonalized to solve for the singular values. \n",
    "\n",
    "Instead of the SVD equation above, the Golub-Kahan method decomposes the original matrix $A$ into the matrices: $P\\,$, $Q\\,$, $J$ below, with $J$ as the final bidiagonal matrix. $P$ and $Q$ are **unitary matrices** . The decomposition of matrix $A$ and the equation rewritten in terms of $J$ for clarity with the diagram to follow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A = P\\,J\\,Q^{T}\\quad\\quad\\quad J = P^{T}A\\,Q$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a matrix $A$ below, where non-zero entries are represented by dots:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/matrix1.png\"style=\"width: 28%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $A$ is a dense matrix. There is another bidiagonalization technique for sparse matrices; the Golub-Kahan-Lanczos method. This sparse method also referred to as the Lanczos bidiagonalization [5].\n",
    "\n",
    "\n",
    "The diagram below demonstrates Golub-Kahan bidiagonalization [6], [4].\n",
    "The basics of what's going on in the diagram:\n",
    "\n",
    "   1. choose the first column, marked by $\\mathbf{X}\\,$, to compute our Householder vector\n",
    "   \n",
    "   2. then apply the Householder reflector (using the Householder vector) to the left of the matrix $A$\n",
    "   \n",
    "   3. choose the first row, marked by $\\mathbf{X}\\,$, to compute our Householder vector\n",
    "   \n",
    "   4. apply the Householder reflector (using the Householder vector) to the right of the matrix $A$\n",
    "   \n",
    "   5. repeat steps 1-4 until there are no more rows and/or columns to choose\n",
    "   \n",
    "   \n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Bidiag.png\"style=\"width: 85%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final bidiagonalized matrix is $J$, while $P$ and $Q$ are made up of the matrix products of the alternating Householder reflectors applied to the left and right of $A$: $U_{1}$, $U_{2}$,$U_{3}$, ..., and $V_{1}$,$V_{2}$, ..., respectively. \n",
    "\n",
    "It is important to note that the length of the alternating rows and columns we use to compute the Householder vectors get smaller with each step as we approach the final matrix $J$. The corresponding Householder reflectors shrink in dimension as well.\n",
    "\n",
    "There are 2 equivalent versions of bidiagonalization; **upper** and **lower**. This diagram shows the upper bidiagonalization, with the second diagonal located **above** the main diagonal. Upper and lower diagonal matrices are equivalent (need citation). Bidiagonalization is performed on matrices $A$ with shape ($m\\;x\\;n$) where $m \\geq n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Householder Vectors and Reflectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know Householder reflectors are used in bidiagonalization, QR factorization, and SVD. But... \n",
    "\n",
    "What are Householder vectors and Householder reflectors?? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember a matrix times a vector is essentially just shifting the vector; rotating and/or stretching it. A **Householder reflector is a matrix that shifts a vector to be non-zero in its first element and zero everywhere else while maintaining the original vector's Euclidean norm**, or distance from the origin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, given a column or row vector: $z$ from our original matrix: $A$, we'd like to chose our **Householder reflector: $P$**, such that: \n",
    "\n",
    "$$Pz = \\big\\|z\\big\\|_{2}e_{1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To gain some further intuition about how the **Householder reflector:** $P$, is caluclated we'll look at this geometrically with a 2-dimensional example [7]:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/reflector1.png\"style=\"width: 35%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have taken the original vector: $z$ applied the reflector: $P$ such that now $Pz$ lies on the x axis.\n",
    "We can also rewrite the reflector equation to express it as a sum of 2 vectors:\n",
    "\n",
    "$$Pz = \\big\\|z\\big\\|_{2}e_{1} = z + v$$\n",
    "\n",
    "where **$v$** is the **Householder vector** and by definition: $$v = \\big\\|z\\big\\|_{2}e_{1} - z$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/reflector2.png\"style=\"width: 35%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term reflector is used because we say that $z$ has been reflected about the mirror onto the axis. It is important to remember this is not a projection; it is a reflection. $Pz$ maintains the same length as $z$. The way we have set the problem up geometrically, our mirror is a perpendicular bisector of $v$. We can now solve for $P$ using the geometric relationships between the vectors: $z$, $v$, and our mirror."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/reflector3.png\"style=\"width: 35%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by finding the length of the vector: $w$. Adding $w$ to $z$ would get us to the mirror:\n",
    "\n",
    "$$\\big\\|w\\big\\| = \\big\\|z\\big\\|cos\\,\\theta \\quad\\quad cos\\,\\theta = \\frac{-z^{T}v}{\\big\\|z\\big\\|\\big\\|v\\big\\|}\\quad\\Longrightarrow\\quad \\big\\|w\\big\\|= \\frac{-z^{T}v}{\\big\\|v\\big\\|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $w$ has the same direction as $v$, its direction is:\n",
    "\n",
    "$$\\hat{w} = \\frac{v}{\\big\\|v\\big\\|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting length and direction together we get:\n",
    "\n",
    "$$w =\\hat{w}\\big\\|w\\big\\|\\quad\\Longrightarrow\\quad -\\frac{v\\,(z^{T}v)}{\\big\\|v\\big\\|\\big\\|v\\big\\|}\\quad\\Longrightarrow\\quad -\\frac{v\\,(z^{T}v)}{v^{T}v}$$\n",
    "\n",
    "But again, this vector $w$ will only get us to the mirror. We want the vector that will get us to the reflection $Pz$. All we need to do is multiply by 2:\n",
    "\n",
    "$$Pz = z - 2\\frac{v\\,(z^{T}v)}{v^{T}v}$$ \n",
    "\n",
    "Rearranging the scalar $(z^{T}v)$ to $(v^{T}z)$ and solving for our Householder reflector P:\n",
    "\n",
    "$$P = I - \\frac{2}{v^{T}v}vv^{T}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a brief example algorithm; i.e. it does not do error handling. Our Householder vector is $v$. To see how the algorithm follows the explanation above I added print statements in the function. We can see how the bidiagonal is being created step by step.\n",
    "\n",
    "Also note, I added a helper function to eliminate issues from round-off error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_lowVal_zero(X):\n",
    "    low_values_indices = abs(X) < 9e-15   # where values are low\n",
    "    X[low_values_indices] = 0             # all low values set to 0\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 3, 0, 2, 5],\n",
       "       [2, 1, 2, 1, 7],\n",
       "       [4, 4, 0, 3, 8],\n",
       "       [5, 6, 1, 3, 1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[4, 3, 0, 2, 5], [2, 1, 2, 1, 7], [4, 4, 0, 3, 8], [5, 6, 1, 3, 1]])\n",
    "J = A.copy(); J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Householder(x, i):\n",
    "    alpha = -np.sign(x[i]) * np.linalg.norm(x)\n",
    "    e = np.zeros(len(x)); e[i] = 1.0\n",
    "    \n",
    "    v = (x - alpha * e)\n",
    "    w = v / np.linalg.norm(v)\n",
    "    P = np.eye(len(x)) - 2 * np.outer(w, w.T)\n",
    "    \n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Golub_Kahan(X):\n",
    "    col = X.shape[1]\n",
    "    row = X.shape[0]\n",
    "    \n",
    "    J = X.copy()\n",
    "    count = 1\n",
    "    for i in range(col - 2):\n",
    "        # column\n",
    "        h = np.zeros(len(J[:, i]))\n",
    "        h[i:] = J[i:, i]\n",
    "        P = Householder(h, i)\n",
    "        J = set_lowVal_zero(P @ J)\n",
    "        print(J, '\\n')\n",
    "\n",
    "        # row\n",
    "        h = np.zeros(len(J[i, :]))\n",
    "        h[i+1:] = J[i, i+1:] \n",
    "        Q = Householder(h, i+1)\n",
    "        J = set_lowVal_zero(J @ Q)\n",
    "        print(J, '\\n')\n",
    "        \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.81024968 -7.6822128  -1.15233192 -4.73736456 -9.09061848]\n",
      " [ 0.         -0.80897324  1.80485901 -0.14093516  4.61383225]\n",
      " [ 0.          0.38205352 -0.39028198  0.71812968  3.22766449]\n",
      " [ 0.          1.47756691  0.51214752  0.1476621  -4.96541939]] \n",
      "\n",
      "[[ -7.81024968  12.86181284   0.           0.           0.        ]\n",
      " [  0.          -2.88761934   1.68826598  -0.62026207   3.69404277]\n",
      " [  0.          -2.73902218  -0.56534578  -0.00157705   1.84660564]\n",
      " [  0.           2.52670888   0.57099479   0.38958976  -4.50117983]] \n",
      "\n",
      "[[ -7.81024968  12.86181284   0.           0.           0.        ]\n",
      " [  0.           4.71432346  -0.39959864   0.58964563  -5.74802607]\n",
      " [  0.           0.          -1.31761499   0.43435941  -1.55542416]\n",
      " [  0.           0.           1.2649524   -0.01255541  -1.36285588]] \n",
      "\n",
      "[[ -7.81024968  12.86181284   0.           0.           0.        ]\n",
      " [  0.           4.71432346   5.79199143   0.           0.        ]\n",
      " [  0.           0.           1.67874107   0.1490065    1.22627369]\n",
      " [  0.           0.           1.26396158  -0.01246105  -1.36377572]] \n",
      "\n",
      "[[ -7.81024968  12.86181284   0.           0.           0.        ]\n",
      " [  0.           4.71432346   5.79199143   0.           0.        ]\n",
      " [  0.           0.          -2.10137347  -0.11154278  -0.15934145]\n",
      " [  0.           0.           0.          -0.09958124  -1.82708557]] \n",
      "\n",
      "[[ -7.81024968  12.86181284   0.           0.           0.        ]\n",
      " [  0.           4.71432346   5.79199143   0.           0.        ]\n",
      " [  0.           0.          -2.10137347   0.19450319   0.        ]\n",
      " [  0.           0.           0.           1.55389757  -0.9662093 ]] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -7.81024968,  12.86181284,   0.        ,   0.        ,   0.        ],\n",
       "       [  0.        ,   4.71432346,   5.79199143,   0.        ,   0.        ],\n",
       "       [  0.        ,   0.        ,  -2.10137347,   0.19450319,   0.        ],\n",
       "       [  0.        ,   0.        ,   0.        ,   1.55389757,  -0.9662093 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Golub_Kahan(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **bidiagonal matrix**: a matrix with non-zero entries along the main diagonal and either the diagonal above (upper) or below (lower) with zeroes elsewhere\n",
    "\n",
    "\n",
    "- **orthogonal columns/ rows**: columns/ rows are perpendicular to one another\n",
    "\n",
    "\n",
    "- **orthogonal matrix**: when a matrix $A$ times its transpose $A^{T}$ is the identity matrix $I$\n",
    "\n",
    "\n",
    "- **singular values**: the relative importance of factors in SVD. Also, the square roots of the eigenvalues of the symmetric nxn matrix $A^{T}A$ listed with their values in decreasing order\n",
    "\n",
    "\n",
    "- **ill-conditioned**: when the approximation of the solutions $x$ to the equation $Ax = b$ is above a level of inaccuracy, due to the values of the matrix $A$, i.e. when a small error in $b$ may cause a large error in $x$\n",
    "\n",
    "\n",
    "- **rank deficient**: for an mxn matrix $A$, when the number of linearly independent rows is less than m\n",
    "\n",
    "\n",
    "- **unitary matrix**: similar to an orthogonal matrix, but holds for complex matrices, where the product of a matrix $A$ and its complex conjugate transpose $A^*$ is the identity matrix $I$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[1] G. H. Golub, W. Kahan, \"Calculating the Singular Values and Pseudoinverse of a Matrix,\" SIAM J. Numer. Anal. 2, 205â€“224 (1965).\n",
    "\n",
    "\n",
    "[2] R. Thomas, MSAN Numerical Linear Algebra Course Notes: Topic Modeling with NMF and SVD. University of San Francisco (2017). https://github.com/fastai/numerical-linear-algebra\n",
    "\n",
    "\n",
    "[3] Video Tutorials All in One, \"Singular Value Decomposition\" Stanford University, YouTube, 13 April (2016).\n",
    "https://www.youtube.com/watch?v=P5mlg91as1c. \n",
    "\n",
    "\n",
    "[4] M. Plesinger, \"Some Remarks on Bidiagonalization and Its Implementation,\" PhD Conference: Institute of Computer Science, Prague (2005).\n",
    "http://www2.cs.cas.cz/mweb/download/publi/Ples2006.pdf\n",
    "\n",
    "\n",
    "[5] A. Bjork, \"A Bidiagonalization Algorithm for Solving Large and Sparse Ill-posed Systems of Linear Equations,\" BIT Numerical Mathematics. 28(3), 659-670 (1988).\n",
    "https://link.springer.com/article/10.1007/BF01941141\n",
    "\n",
    "\n",
    "\n",
    "[6] G. Fasshauer, 444/577 Handouts and Worksheets: Chapter 12. Illinois Institue of Technology. http://www.math.iit.edu/~fass/477577_Chapter_12.pdf\n",
    "\n",
    "\n",
    "[7] T. Driscoll, \"Householder QR\" MATH426, YouTube, 23 September (2015).\n",
    "https://www.youtube.com/watch?v=d-yPM-bxREs\n",
    "\n",
    "\n",
    "\n",
    "[8] G. H. Golub, C. F. Van Loan, Matrix Computations 3rd edition, The John Hopkins University Press, Baltimore, (1996).\n",
    "\n",
    "\n",
    "\n",
    "[9] L. N. Trefethen and D. Bau, Numerical Linear Algebra, SIAM (1997)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
